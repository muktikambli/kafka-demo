# ğŸ§© Kafka Demo Project

## Overview
This **Kafka Demo Project** demonstrates how multiple microservices (Order, Payment, and Notification) communicate asynchronously using **Apache Kafka**.  
It covers essential Kafka concepts such as:
- Producer and Consumer APIs
- Topic creation programmatically
- JSON serialization and deserialization
- Multi-topic communication pattern
- Threaded consumer setup

## ğŸ—ï¸ Architecture
```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Order App  â”‚â”€â”€â–º(orders topic)â”€â”€â–ºâ”‚ Payment App â”‚â”€â”€â–º(payments topic)â”€â”€â–ºâ”‚ Notification App â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each service is represented by a **Producer** and a **Consumer** pair:
- `OrderProducer` â†’ Sends new order messages  
- `PaymentConsumer` â†’ Processes payments upon receiving orders  
- `PaymentProducer` â†’ Publishes payment confirmation  
- `NotificationConsumer` â†’ Sends notifications based on payments  
- `NotificationProducer` â†’ Logs / confirms successful notifications  

## âš™ï¸ Technologies Used
- **Java 17+**
- **Apache Kafka 3.x**
- **Maven**
- **Jackson** (for JSON serialization/deserialization)
- **Eclipse IDE / IntelliJ IDEA**

## ğŸ§¾ Project Structure

```
kafka-demo/
â”œâ”€â”€ src/main/java/com/example/kafka/
â”‚   â”œâ”€â”€ admin/TopicManager.java
â”‚   â”œâ”€â”€ config/ConfigLoader.java
â”‚   â”œâ”€â”€ consumer/
â”‚   â”‚   â”œâ”€â”€ OrderConsumer.java
â”‚   â”‚   â”œâ”€â”€ PaymentConsumer.java
â”‚   â”‚   â””â”€â”€ NotificationConsumer.java
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ Order.java
â”‚   â”‚   â”œâ”€â”€ Payment.java
â”‚   â”‚   â””â”€â”€ Notification.java
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â”œâ”€â”€ OrderProducer.java
â”‚   â”‚   â”œâ”€â”€ PaymentProducer.java
â”‚   â”‚   â””â”€â”€ NotificationProducer.java
â”‚   â””â”€â”€ App.java
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ application.properties
â””â”€â”€ pom.xml
```

## âš¡ How It Works

1. **Topics are created programmatically**  
   Using `TopicManager`, the app ensures that all required topics exist:
   ```java
   topicManager.createTopicIfNotExists("orders", 1, (short)1);
   topicManager.createTopicIfNotExists("payments", 1, (short)1);
   topicManager.createTopicIfNotExists("notifications", 1, (short)1);
   ```

2. **Producers send messages**
   Each producer serializes its domain object (Order, Payment, Notification) into JSON and sends it to Kafka.

3. **Consumers run in separate threads**
   Each consumer listens to its assigned topic, deserializes the JSON, and processes the message.

4. **Chained event flow**
   - OrderProducer â†’ sends new orders  
   - PaymentConsumer â†’ consumes orders, processes payment  
   - PaymentProducer â†’ sends payment success  
   - NotificationConsumer â†’ consumes payments, sends notification  

## ğŸ§ª Running the Application

### 1. Start Kafka and Zookeeper
If youâ€™re running Kafka locally:
```bash
cd C:\kafka
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

### 2. Check topics (optional)
```bash
.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092
```

### 3. Run the Java Application
You can run `App.java` from Eclipse or via terminal:
```bash
mvn clean package
java -jar target/kafka-demo-1.0-SNAPSHOT.jar
```

### 4. Observe the logs
Youâ€™ll see:
```
âœ… All topics created successfully!
âœ… Consumers started...
âœ… Sending Orders...
âœ… Sending Payments...
âœ… Sending Notifications...
âœ… All messages sent successfully!
```

## ğŸ§° Configuration (application.properties)
Example config:
```properties
bootstrap.servers=localhost:9092
topics=orders,payments,notifications
```

## ğŸš€ Next Steps (Future Enhancements)
- Add schema validation using **Avro**  
- Introduce **Dead Letter Queue (DLQ)** handling  
- Use **Kafka Streams** for real-time transformation  
- Containerize with **Docker Compose**  
- Add **unit/integration tests** with Testcontainers  

## ğŸ‘¨â€ğŸ’» Author
**Mukti Gosavi**  
Kafka Demo for multi-service event-driven architecture  
ğŸ’¡ *Developed as a learning and reference project for Apache Kafka integrations.*
